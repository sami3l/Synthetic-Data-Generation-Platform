# Backend - Synthetic Data Generation Platform

## ğŸ¯ Vue d'ensemble

API Backend FastAPI pour une plateforme complÃ¨te de gÃ©nÃ©ration de donnÃ©es synthÃ©tiques utilisant l'intelligence artificielle. Cette plateforme supporte plusieurs modÃ¨les d'IA (CTGAN, TVAE) avec des fonctionnalitÃ©s avancÃ©es d'optimisation bayÃ©sienne et de stockage cloud via Supabase.

La plateforme est conÃ§ue pour permettre aux utilisateurs de :
- Uploader des datasets dans diffÃ©rents formats
- Configurer des modÃ¨les de gÃ©nÃ©ration de donnÃ©es synthÃ©tiques
- Optimiser automatiquement les hyperparamÃ¨tres
- TÃ©lÃ©charger les donnÃ©es gÃ©nÃ©rÃ©es
- Suivre les performances et les mÃ©triques

## ğŸš€ FonctionnalitÃ©s Principales

### ğŸ¤– GÃ©nÃ©ration de DonnÃ©es SynthÃ©tiques
- **ModÃ¨les IA supportÃ©s :**
  - **CTGAN** (Conditional Tabular GAN) - GÃ©nÃ©ration conditionnelle de donnÃ©es tabulaires
  - **TVAE** (Tabular Variational AutoEncoder) - GÃ©nÃ©ration basÃ©e sur les autoencodeurs variationnels
- **Optimisation BayÃ©sienne** - Optimisation automatique des hyperparamÃ¨tres    
- **Configuration flexible** - ParamÃ¨tres personnalisables par modÃ¨le

### ğŸ“Š Optimisation des HyperparamÃ¨tres  
- **Grid Search** - Recherche exhaustive dans une grille de paramÃ¨tres
- **Random Search** - Recherche alÃ©atoire optimisÃ©e
- **Optimisation BayÃ©sienne** avec scikit-optimize pour une recherche intelligente
- **MÃ©triques de qualitÃ©** automatiques pour Ã©valuer les rÃ©sultats

### ğŸ“ Gestion des DonnÃ©es
- **Upload multi-format :** CSV, JSON, Excel (.xlsx), 
- **Validation automatique** des datasets uploadÃ©s
- **Analyse des types de donnÃ©es** et dÃ©tection des colonnes catÃ©gorielles
- **Stockage sÃ©curisÃ©** avec Supabase Storage
- **URLs temporaires** pour tÃ©lÃ©chargement sÃ©curisÃ© des rÃ©sultats

### ğŸ” SÃ©curitÃ© et Authentification
- **JWT Authentication** avec tokens d'accÃ¨s et de rafraÃ®chissement
- **Gestion des rÃ´les** (utilisateur standard/administrateur)
- **Middleware de sÃ©curitÃ©** avec headers automatiques
- **Limitation de taille** des requÃªtes et fichiers uploadÃ©s
- **CORS configurÃ©** pour l'intÃ©gration frontend

### ğŸ“ˆ Monitoring et Analytics
- **Logging complet** de toutes les requÃªtes et opÃ©rations
- **Statistiques de performance** en temps rÃ©el
- **Dashboard analytique** pour les administrateurs
- **Suivi des requÃªtes** par utilisateur
- **MÃ©triques de gÃ©nÃ©ration** et d'optimisation

### ğŸ‘¥ Gestion des Utilisateurs et Administration
- **Profils utilisateur** avec informations dÃ©taillÃ©es
- **SystÃ¨me de notifications** push intÃ©grÃ©
- **Logs d'actions admin** pour traÃ§abilitÃ©
- **Gestion des datasets** uploadÃ©s par utilisateur
- **Approbation des requÃªtes** par les administrateurs

## ğŸ›  Architecture Technique

### Stack Technologique
- **Framework :** FastAPI avec support asynchrone
- **Base de donnÃ©es :** PostgreSQL avec SQLAlchemy 2.0
- **IA/ML :** SDV (Synthetic Data Vault), scikit-optimize, pandas, numpy
- **Stockage cloud :** Supabase Storage
- **Authentification :** JWT avec python-jose[cryptography]
- **Migrations :** Alembic pour la gestion des versions DB
- **Validation :** Pydantic v2 pour les schÃ©mas de donnÃ©es

### Architecture des ModÃ¨les
La plateforme utilise une architecture modulaire avec :
- **ModÃ¨les SQLAlchemy** pour la persistance des donnÃ©es
- **Services mÃ©tier** pour la logique applicative
- **Routeurs FastAPI** pour les endpoints API
- **SchÃ©mas Pydantic** pour la validation et sÃ©rialisation
- **DÃ©pendances** pour l'injection et l'authentification

### Structure DÃ©taillÃ©e du Projet
```
synth-backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                    # Point d'entrÃ©e FastAPI
â”‚   â”œâ”€â”€ ai/                        # Services IA et modÃ¨les
â”‚   â”‚   â”œâ”€â”€ models/                # DÃ©finitions des modÃ¨les IA
â”‚   â”‚   â””â”€â”€ services/              # Services de gÃ©nÃ©ration
â”‚   â”œâ”€â”€ auth/                      # Authentification JWT
â”‚   â”‚   â””â”€â”€ jwt.py                 # Gestion des tokens
â”‚   â”œâ”€â”€ core/                      # Configuration centrale
â”‚   â”‚   â”œâ”€â”€ config.py              # Variables d'environnement
â”‚   â”‚   â”œâ”€â”€ middleware.py          # Middlewares personnalisÃ©s
â”‚   â”‚   â”œâ”€â”€ security.py            # Utilitaires de sÃ©curitÃ©
â”‚   â”‚   â””â”€â”€ supabase.py            # Client Supabase
â”‚   â”œâ”€â”€ data/                      # Stockage des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ datasets/              # Datasets uploadÃ©s
â”‚   â”‚   â””â”€â”€ synthetic/             # DonnÃ©es gÃ©nÃ©rÃ©es
â”‚   â”œâ”€â”€ db/                        # Configuration base de donnÃ©es
â”‚   â”‚   â”œâ”€â”€ database.py            # Connexion SQLAlchemy
â”‚   â”‚   â”œâ”€â”€ deps.py                # DÃ©pendances DB
â”‚   â”‚   â””â”€â”€ session.py             # Gestion des sessions
â”‚   â”œâ”€â”€ dependencies/              # DÃ©pendances FastAPI
â”‚   â”‚   â”œâ”€â”€ auth.py                # DÃ©pendances d'authentification
â”‚   â”‚   â””â”€â”€ roles.py               # Gestion des rÃ´les
â”‚   â”œâ”€â”€ models/                    # ModÃ¨les SQLAlchemy
â”‚   â”‚   â”œâ”€â”€ DataRequest.py         # RequÃªtes de gÃ©nÃ©ration
â”‚   â”‚   â”œâ”€â”€ user.py                # Utilisateurs
â”‚   â”‚   â”œâ”€â”€ UserProfile.py         # Profils utilisateur
â”‚   â”‚   â”œâ”€â”€ UploadedDataset.py     # Datasets uploadÃ©s
â”‚   â”‚   â”œâ”€â”€ Notification.py        # Notifications
â”‚   â”‚   â”œâ”€â”€ AdminActionLog.py      # Logs administrateur
â”‚   â”‚   â””â”€â”€ Optimization*.py       # ModÃ¨les d'optimisation
â”‚   â”œâ”€â”€ routers/                   # Endpoints API
â”‚   â”‚   â”œâ”€â”€ auth.py                # Authentification
â”‚   â”‚   â”œâ”€â”€ data.py                # Gestion des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ dataset.py             # Gestion des datasets
â”‚   â”‚   â”œâ”€â”€ generation.py          # GÃ©nÃ©ration v1
â”‚   â”‚   â”œâ”€â”€ generation_v2.py       # GÃ©nÃ©ration v2 amÃ©liorÃ©e
â”‚   â”‚   â”œâ”€â”€ optimization.py        # Optimisation bayÃ©sienne
â”‚   â”‚   â”œâ”€â”€ upload_async.py        # Upload asynchrone
â”‚   â”‚   â”œâ”€â”€ user.py                # Gestion utilisateurs
â”‚   â”‚   â”œâ”€â”€ admin.py               # Administration
â”‚   â”‚   â”œâ”€â”€ notification.py        # Notifications
â”‚   â”‚   â””â”€â”€ stats.py               # Statistiques
â”‚   â”œâ”€â”€ schemas/                   # SchÃ©mas Pydantic
â”‚   â”‚   â”œâ”€â”€ user.py                # SchÃ©mas utilisateur
â”‚   â”‚   â”œâ”€â”€ DataRequest.py         # SchÃ©mas de requÃªtes
â”‚   â”‚   â”œâ”€â”€ datasets.py            # SchÃ©mas datasets
â”‚   â”‚   â”œâ”€â”€ Optimization.py        # SchÃ©mas optimisation
â”‚   â”‚   â””â”€â”€ Notification.py        # SchÃ©mas notifications
â”‚   â””â”€â”€ services/                  # Services mÃ©tier
â”œâ”€â”€ alembic/                       # Migrations de base de donnÃ©es
â”‚   â”œâ”€â”€ versions/                  # Fichiers de migration
â”‚   â””â”€â”€ env.py                     # Configuration Alembic
â”œâ”€â”€ requirements.txt               # DÃ©pendances Python
â”œâ”€â”€ requirements-minimal.txt       # DÃ©pendances minimales
â”œâ”€â”€ .env.example                   # Template variables d'environnement
â””â”€â”€ alembic.ini                    # Configuration Alembic
```

## ğŸš€ Installation et Configuration

### 1. PrÃ©requis
```bash
Python 3.9+ (recommandÃ© 3.12+)
PostgreSQL 12+
pip (gestionnaire de paquets Python)
```

### 2. Installation rapide
```bash
# 1. Cloner le repository et naviguer vers le backend
cd synth-backend

# 2. CrÃ©er un environnement virtuel (recommandÃ©)
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Configurer les variables d'environnement
copy .env.example .env
# Ã‰diter le fichier .env avec vos paramÃ¨tres

# 5. Initialiser la base de donnÃ©es
alembic upgrade head

# 6. DÃ©marrer le serveur de dÃ©veloppement
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 3. Configuration de l'environnement

Copiez `.env.example` vers `.env` et configurez les variables suivantes :

```env
# Base de donnÃ©es PostgreSQL
DATABASE_URL=postgresql+psycopg2://username:password@localhost:5432/synth_db
ASYNC_DATABASE_URL=postgresql+asyncpg://username:password@localhost:5432/synth_db

# JWT Authentication
SECRET_KEY=your-super-secret-jwt-key-here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Supabase (pour le stockage cloud)
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-supabase-anon-key
SUPABASE_BUCKET_NAME=synthetic-datasets

# Configuration application
APP_NAME=Synthetic Data Generation Platform
APP_VERSION=1.0.0
DEBUG=True

# Limites de fichiers
MAX_FILE_SIZE_MB=500
SUPPORTED_FILE_TYPES=csv,json,xlsx,parquet

# Configuration gÃ©nÃ©ration
DEFAULT_SAMPLE_SIZE=1000
MAX_SAMPLE_SIZE=100000
DEFAULT_EPOCHS=100
MAX_EPOCHS=500
```

### 4. Configuration de la base de donnÃ©es

```bash
# CrÃ©er la base de donnÃ©es PostgreSQL
createdb synth_db

# Ou via psql
psql -U postgres -c "CREATE DATABASE synth_db;"

# ExÃ©cuter les migrations
alembic upgrade head

# VÃ©rifier les tables crÃ©Ã©es
alembic current
```

## ğŸ“‹ Commandes Utiles

### Gestion de l'application
```bash
# DÃ©marrer le serveur de dÃ©veloppement
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# DÃ©marrer en mode production
uvicorn app.main:app --host 0.0.0.0 --port 8000

# Avec Gunicorn (production)
gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

### Gestion des migrations Alembic
```bash
# CrÃ©er une nouvelle migration
alembic revision --autogenerate -m "Description de la migration"

# Appliquer toutes les migrations
alembic upgrade head

# Voir l'historique des migrations
alembic history

# Revenir Ã  une migration spÃ©cifique
alembic downgrade <revision_id>

# Voir le statut actuel
alembic current
```

### Gestion des dÃ©pendances
```bash
# Installer les dÃ©pendances complÃ¨tes
pip install -r requirements.txt

# Installer les dÃ©pendances minimales
pip install -r requirements-minimal.txt

# Mettre Ã  jour requirements.txt
pip freeze > requirements.txt

# Installer une nouvelle dÃ©pendance
pip install package_name
pip freeze > requirements.txt
```

## ğŸ”§ Configuration AvancÃ©e

### Variables d'environnement complÃ¨tes

```env
# === BASE DE DONNÃ‰ES ===
DATABASE_URL=postgresql+psycopg2://username:password@localhost:5432/synth_db
ASYNC_DATABASE_URL=postgresql+asyncpg://username:password@localhost:5432/synth_db

# === AUTHENTIFICATION JWT ===
SECRET_KEY=your-super-secret-jwt-key-minimum-32-characters
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# === SUPABASE STORAGE ===
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-supabase-service-role-key
SUPABASE_BUCKET_NAME=synthetic-datasets

# === CONFIGURATION APPLICATION ===
APP_NAME=Synthetic Data Generation Platform
APP_VERSION=1.0.0
DEBUG=True
ENVIRONMENT=development  # development, staging, production

# === LIMITES ET RESTRICTIONS ===
MAX_FILE_SIZE_MB=500
SUPPORTED_FILE_TYPES=csv,json,xlsx,parquet
MAX_CONCURRENT_GENERATIONS=5
REQUEST_TIMEOUT_SECONDS=3600

# === GÃ‰NÃ‰RATION DE DONNÃ‰ES ===
DEFAULT_SAMPLE_SIZE=1000
MAX_SAMPLE_SIZE=100000
MIN_SAMPLE_SIZE=100
DEFAULT_EPOCHS=100
MAX_EPOCHS=500
MIN_EPOCHS=10

# === OPTIMISATION ===
MAX_OPTIMIZATION_TRIALS=100
DEFAULT_OPTIMIZATION_TRIALS=20
OPTIMIZATION_TIMEOUT_HOURS=24

# === SÃ‰CURITÃ‰ ===
CORS_ORIGINS=http://localhost:3000,http://localhost:8081
ALLOWED_HOSTS=localhost,127.0.0.1
MAX_REQUEST_SIZE_MB=100

# === LOGGING ===
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR
LOG_FILE_PATH=logs/app.log
LOG_ROTATION_SIZE_MB=10
LOG_BACKUP_COUNT=5

# === NOTIFICATIONS ===
ENABLE_PUSH_NOTIFICATIONS=true
NOTIFICATION_BATCH_SIZE=100

# === MONITORING ===
METRICS_ENABLED=true
PERFORMANCE_MONITORING=true
```

### Configuration Supabase

Pour configurer Supabase Storage :

1. **CrÃ©er un bucket :**
```sql
-- Dans l'interface Supabase SQL Editor
INSERT INTO storage.buckets (id, name, public)
VALUES ('synthetic-datasets', 'synthetic-datasets', false);
```

2. **Configurer les politiques RLS :**
```sql
-- Politique pour permettre l'upload aux utilisateurs authentifiÃ©s
CREATE POLICY "Users can upload their own datasets" ON storage.objects
FOR INSERT WITH CHECK (
  bucket_id = 'synthetic-datasets' AND
  auth.uid()::text = (storage.foldername(name))[1]
);

-- Politique pour permettre le tÃ©lÃ©chargement
CREATE POLICY "Users can download their own datasets" ON storage.objects
FOR SELECT USING (
  bucket_id = 'synthetic-datasets' AND
  auth.uid()::text = (storage.foldername(name))[1]
);
```

### Configuration PostgreSQL

Configuration optimale pour PostgreSQL :

```sql
-- postgresql.conf recommandations
shared_buffers = 256MB
effective_cache_size = 1GB
work_mem = 4MB
maintenance_work_mem = 64MB
checkpoint_segments = 32
checkpoint_completion_target = 0.7
wal_buffers = 16MB
default_statistics_target = 100
```

### Middleware et sÃ©curitÃ©

Le backend inclut plusieurs middlewares de sÃ©curitÃ© :

```python
# Middlewares automatiquement appliquÃ©s
SecurityHeadersMiddleware     # Headers de sÃ©curitÃ©
RequestSizeLimitMiddleware   # Limite taille requÃªtes
LoggingMiddleware           # Logging automatique
PerformanceMonitoringMiddleware # MÃ©triques de performance
CORSMiddleware             # Configuration CORS
```

### Configuration des logs

```python
# Configuration logging dans main.py
logging.basicConfig(
    level=getattr(logging, os.getenv('LOG_LEVEL', 'INFO')),
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(os.getenv('LOG_FILE_PATH', 'logs/app.log')),
        logging.StreamHandler()
    ]
)
```

## ğŸ“š API Documentation

L'API est entiÃ¨rement documentÃ©e et accessible via :
- **Swagger UI :** `http://localhost:8000/docs` (interface interactive)
- **ReDoc :** `http://localhost:8000/redoc` (documentation statique)

### Endpoints principaux

#### ğŸ” Authentification (`/auth`)
```http
POST /auth/register          # Inscription d'un nouvel utilisateur
POST /auth/login             # Connexion et gÃ©nÃ©ration de token
POST /auth/refresh           # RafraÃ®chissement du token
GET  /auth/me                # RÃ©cupÃ©ration du profil utilisateur
POST /auth/logout            # DÃ©connexion
```

#### ğŸ‘¤ Gestion des utilisateurs (`/users`)
```http
GET    /users/profile        # Profil de l'utilisateur connectÃ©
PUT    /users/profile        # Mise Ã  jour du profil
POST   /users/push-token     # Enregistrement token push notifications
DELETE /users/account        # Suppression du compte
```

#### ğŸ“¤ Upload de donnÃ©es (`/upload`)
```http
POST /upload/dataset         # Upload d'un dataset (CSV, JSON, Excel, Parquet)
GET  /upload/datasets        # Liste des datasets de l'utilisateur
GET  /upload/datasets/{id}   # DÃ©tails d'un dataset spÃ©cifique
DELETE /upload/datasets/{id} # Suppression d'un dataset
```

#### ğŸ¤– GÃ©nÃ©ration de donnÃ©es (`/generation`)
```http
POST /generation/start       # DÃ©marrer une nouvelle gÃ©nÃ©ration
GET  /generation/requests    # Liste des requÃªtes de l'utilisateur
GET  /generation/status/{id} # Statut d'une gÃ©nÃ©ration
GET  /generation/download/{id} # TÃ©lÃ©charger les rÃ©sultats
DELETE /generation/requests/{id} # Annuler une requÃªte
```

#### ğŸ”§ GÃ©nÃ©ration avancÃ©e (`/generation-v2`)
```http
POST /generation-v2/start    # GÃ©nÃ©ration avec paramÃ¨tres avancÃ©s
GET  /generation-v2/config   # Configuration par dÃ©faut
POST /generation-v2/validate # Validation des paramÃ¨tres
```

#### ğŸ“Š Optimisation (`/optimization`)
```http
POST /optimization/start     # DÃ©marrer une optimisation bayÃ©sienne
GET  /optimization/trials/{id} # RÃ©sultats des essais d'optimisation
GET  /optimization/best/{id} # Meilleurs paramÃ¨tres trouvÃ©s
PUT  /optimization/stop/{id} # ArrÃªter une optimisation en cours
```

#### ï¿½ Statistiques (`/stats`)
```http
GET /stats/dashboard         # Dashboard utilisateur
GET /stats/system           # Statistiques systÃ¨me (admin uniquement)
GET /stats/performance      # MÃ©triques de performance
GET /stats/usage            # Statistiques d'utilisation
```

#### ğŸ”” Notifications (`/notifications`)
```http
GET    /notifications        # Notifications de l'utilisateur
POST   /notifications/read   # Marquer comme lues
DELETE /notifications/{id}   # Supprimer une notification
```

#### ğŸ‘‘ Administration (`/admin`)
```http
GET    /admin/users          # Liste tous les utilisateurs
GET    /admin/requests       # Toutes les requÃªtes de gÃ©nÃ©ration
POST   /admin/approve/{id}   # Approuver une requÃªte
POST   /admin/reject/{id}    # Rejeter une requÃªte
GET    /admin/logs           # Logs d'actions administrateur
POST   /admin/users/{id}/toggle # Activer/dÃ©sactiver un utilisateur
```

### Authentification

La plupart des endpoints nÃ©cessitent une authentification via JWT :

```http
Authorization: Bearer <your-jwt-token>
```

### Formats de rÃ©ponse

Toutes les rÃ©ponses suivent un format standardisÃ© :

```json
{
  "success": true,
  "data": { ... },
  "message": "Operation completed successfully",
  "timestamp": "2024-12-13T10:30:00Z"
}
```

En cas d'erreur :
```json
{
  "success": false,
  "error": {
    "code": "VALIDATION_ERROR",
    "message": "Invalid input parameters",
    "details": { ... }
  },
  "timestamp": "2024-12-13T10:30:00Z"
}
```

## ğŸ¯ Configuration des ModÃ¨les de GÃ©nÃ©ration

### CTGAN (Conditional Tabular GAN)

Le modÃ¨le CTGAN est optimal pour les donnÃ©es tabulaires avec des relations complexes :

```json
{
  "model_type": "ctgan",
  "epochs": 100,              // Nombre d'Ã©poques d'entraÃ®nement
  "batch_size": 500,          // Taille des lots
  "generator_dim": [256, 256], // Architecture du gÃ©nÃ©rateur
  "discriminator_dim": [256, 256], // Architecture du discriminateur
  "generator_lr": 2e-4,       // Taux d'apprentissage du gÃ©nÃ©rateur
  "discriminator_lr": 2e-4,   // Taux d'apprentissage du discriminateur
  "discriminator_steps": 1,   // Ã‰tapes d'entraÃ®nement du discriminateur
  "log_frequency": true,      // Logging des mÃ©triques
  "pac": 10                   // Facteur PAC (packing)
}
```

**ParamÃ¨tres recommandÃ©s selon la taille du dataset :**
- **Petit dataset (< 1000 lignes) :** epochs=200, batch_size=100
- **Dataset moyen (1000-10000) :** epochs=150, batch_size=500
- **Grand dataset (> 10000) :** epochs=100, batch_size=1000

### TVAE (Tabular Variational AutoEncoder)

Le modÃ¨le TVAE est plus rapide et efficace pour les datasets simples :

```json
{
  "model_type": "tvae",
  "epochs": 100,
  "batch_size": 500,
  "embedding_dim": 128,       // Dimension de l'espace latent
  "compress_dims": [128, 128], // Architecture de l'encodeur
  "decompress_dims": [128, 128], // Architecture du dÃ©codeur
  "l2scale": 1e-5,           // RÃ©gularisation L2
  "learning_rate": 1e-3,     // Taux d'apprentissage
  "loss_factor": 2           // Facteur de pondÃ©ration de la perte
}
```

### Optimisation BayÃ©sienne

Configuration pour l'optimisation automatique des hyperparamÃ¨tres :

```json
{
  "model_type": "ctgan",      // ou "tvae"
  "optimization_method": "bayesian",
  "n_trials": 50,            // Nombre d'essais d'optimisation
  "optimization_metric": "quality_score", // MÃ©trique Ã  optimiser
  "search_space": {
    "epochs": [50, 200],
    "batch_size": [100, 1000],
    "learning_rate": [1e-4, 1e-2]
  },
  "acquisition_function": "EI", // Expected Improvement
  "random_state": 42
}
```

### MÃ©triques de qualitÃ© disponibles

La plateforme Ã©value automatiquement la qualitÃ© des donnÃ©es gÃ©nÃ©rÃ©es :

- **Statistical Similarity :** Comparaison des distributions statistiques
- **Correlation Preservation :** Conservation des corrÃ©lations entre variables
- **Privacy Metrics :** Mesures de protection de la vie privÃ©e
- **Machine Learning Efficacy :** Performance sur des tÃ¢ches ML

### Exemple de requÃªte complÃ¨te

```json
{
  "dataset_id": 123,
  "sample_size": 5000,
  "model_config": {
    "model_type": "ctgan",
    "epochs": 150,
    "batch_size": 500,
    "generator_dim": [256, 256],
    "discriminator_dim": [256, 256]
  },
  "optimization_config": {
    "enabled": true,
    "method": "bayesian",
    "n_trials": 20,
    "metric": "quality_score"
  },
  "output_format": "csv",
  "include_metadata": true
}
```

## ğŸ“ˆ Monitoring et Performance

### MÃ©triques surveillÃ©es automatiquement

La plateforme collecte automatiquement plusieurs mÃ©triques :

#### MÃ©triques d'API
- **Temps de rÃ©ponse** par endpoint
- **Taux de succÃ¨s/Ã©chec** des requÃªtes
- **Utilisation de la bande passante**
- **Nombre de requÃªtes concurrentes**

#### MÃ©triques de gÃ©nÃ©ration
- **Temps d'entraÃ®nement** des modÃ¨les
- **QualitÃ© des donnÃ©es gÃ©nÃ©rÃ©es**
- **Utilisation mÃ©moire** pendant la gÃ©nÃ©ration
- **Taux de succÃ¨s** des optimisations

#### MÃ©triques utilisateur
- **ActivitÃ© par utilisateur**
- **Formats de fichiers** les plus utilisÃ©s
- **Tailles de datasets** moyennes
- **DurÃ©e des sessions**

### Dashboard de monitoring

AccÃ¨s aux mÃ©triques via les endpoints :

```http
GET /stats/dashboard        # MÃ©triques utilisateur
GET /stats/system          # MÃ©triques systÃ¨me (admin)
GET /stats/performance     # Performance en temps rÃ©el
```

### Logs structurÃ©s

Tous les logs suivent un format structurÃ© pour faciliter l'analyse :

```json
{
  "timestamp": "2024-12-13T10:30:00Z",
  "level": "INFO",
  "module": "generation_service",
  "user_id": 123,
  "request_id": "req_abc123",
  "message": "Generation completed successfully",
  "metadata": {
    "model_type": "ctgan",
    "sample_size": 5000,
    "duration_seconds": 120.5
  }
}
```

### Alertes et notifications

Le systÃ¨me gÃ©nÃ¨re automatiquement des alertes pour :

- **GÃ©nÃ©rations qui Ã©chouent** plus de 3 fois
- **Temps de rÃ©ponse** > 30 secondes
- **Utilisation mÃ©moire** > 80%
- **Erreurs de base de donnÃ©es**

### Performance et optimisation

#### Recommandations pour la production

1. **Configuration PostgreSQL :**
   - Activer les connexions pooling
   - Configurer `shared_buffers` Ã  25% de la RAM
   - Utiliser des index appropriÃ©s

2. **Configuration FastAPI :**
   - Utiliser Gunicorn avec des workers asyncio
   - Configurer un reverse proxy (Nginx)
   - Activer la compression gzip

3. **Monitoring externe :**
   - IntÃ©grer avec Prometheus/Grafana
   - Configurer des alertes Slack/email
   - Utiliser des health checks

#### Commandes de diagnostic

```bash
# VÃ©rifier l'Ã©tat de la base de donnÃ©es
alembic current

# Tester les connexions
python -c "from app.db.database import engine; print(engine.execute('SELECT 1').scalar())"

# VÃ©rifier l'espace disque
df -h data/

# Monitorer les processus
ps aux | grep uvicorn
```

## ğŸ”’ SÃ©curitÃ© et Bonnes Pratiques

### Mesures de sÃ©curitÃ© implÃ©mentÃ©es

#### Authentification et autorisation
- **JWT stateless** avec expiration automatique
- **Tokens de rafraÃ®chissement** sÃ©curisÃ©s
- **Gestion des rÃ´les** granulaire (user/admin)
- **Validation des permissions** sur chaque endpoint

#### Protection des donnÃ©es
- **Chiffrement des mots de passe** avec bcrypt
- **Validation stricte** des uploads de fichiers
- **Nettoyage automatique** des fichiers temporaires
- **URLs temporaires** pour le tÃ©lÃ©chargement

#### Headers de sÃ©curitÃ© automatiques
```http
X-Content-Type-Options: nosniff
X-Frame-Options: DENY
X-XSS-Protection: 1; mode=block
Strict-Transport-Security: max-age=31536000
Content-Security-Policy: default-src 'self'
```

#### Validation et limitations
- **Limitation de taille** des fichiers (configurable)
- **Validation des types MIME** pour les uploads
- **Rate limiting** sur les endpoints sensibles
- **Timeout** sur les opÃ©rations longues

### Configuration CORS

```python
# Configuration CORS sÃ©curisÃ©e
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS.split(","),
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["*"],
)
```

### Bonnes pratiques de dÃ©ploiement

#### Variables d'environnement sensibles
```bash
# Ne jamais commiter ces valeurs
SECRET_KEY=                 # GÃ©nÃ©rer avec: openssl rand -hex 32
SUPABASE_KEY=              # Utiliser la clÃ© service role
DATABASE_URL=              # Utiliser des credentials forts
```

#### Configuration production
```env
DEBUG=False
ENVIRONMENT=production
LOG_LEVEL=WARNING
CORS_ORIGINS=https://your-domain.com
ALLOWED_HOSTS=your-domain.com
```

#### Recommandations serveur
1. **Utiliser HTTPS** uniquement en production
2. **Configurer un firewall** restrictif
3. **Mettre Ã  jour** rÃ©guliÃ¨rement les dÃ©pendances
4. **Sauvegarder** la base de donnÃ©es quotidiennement
5. **Monitorer** les tentatives d'intrusion

### Audit et conformitÃ©

#### Logs de sÃ©curitÃ©
- **Tentatives de connexion** Ã©chouÃ©es
- **AccÃ¨s admin** et modifications
- **Uploads** et tÃ©lÃ©chargements de fichiers
- **Erreurs d'authentification**

#### Nettoyage automatique
```python
# TÃ¢ches de nettoyage programmÃ©es
- Suppression des fichiers temporaires > 24h
- Nettoyage des tokens expirÃ©s
- Archivage des logs anciens
- Purge des notifications lues
```

#### Compliance RGPD
- **Anonymisation** des donnÃ©es utilisateur
- **Droit Ã  l'effacement** implÃ©mentÃ©
- **Consentement explicite** pour les notifications
- **PortabilitÃ© des donnÃ©es** via export

## ğŸ› Debugging et Troubleshooting

### ProblÃ¨mes frÃ©quents et solutions

#### 1. Erreur de connexion Ã  la base de donnÃ©es

**SymptÃ´me :** `sqlalchemy.exc.OperationalError: could not connect to server`

**Solutions :**
```bash
# VÃ©rifier que PostgreSQL est en cours d'exÃ©cution
# Windows
net start postgresql-x64-13

# Linux/Mac
sudo systemctl start postgresql

# VÃ©rifier la configuration DATABASE_URL
echo $DATABASE_URL

# Tester la connexion
psql -h localhost -U username -d synth_db
```

#### 2. Erreur d'upload Supabase

**SymptÃ´me :** `supabase.StorageException: Unauthorized`

**Solutions :**
```bash
# VÃ©rifier les clÃ©s Supabase
echo $SUPABASE_URL
echo $SUPABASE_KEY

# VÃ©rifier les politiques RLS dans Supabase
# Aller dans Storage > Settings > Policies
```

#### 3. GÃ©nÃ©ration qui Ã©choue

**SymptÃ´me :** GÃ©nÃ©ration reste en statut "processing"

**Solutions :**
```bash
# VÃ©rifier les logs
tail -f logs/app.log

# VÃ©rifier l'utilisation mÃ©moire
free -h

# RÃ©duire la taille du sample si nÃ©cessaire
# Ajuster epochs et batch_size
```

#### 4. Token JWT expirÃ©

**SymptÃ´me :** `401 Unauthorized` sur les requÃªtes authentifiÃ©es

**Solutions :**
```python
# VÃ©rifier la configuration JWT
print(settings.SECRET_KEY)
print(settings.ACCESS_TOKEN_EXPIRE_MINUTES)

# Utiliser le refresh token pour obtenir un nouveau token
POST /auth/refresh
```

### Mode debug avancÃ©

```bash
# Activer le mode debug complet
export DEBUG=True
export LOG_LEVEL=DEBUG

# DÃ©marrer avec logs dÃ©taillÃ©s
uvicorn app.main:app --reload --log-level debug

# Suivre les logs en temps rÃ©el
tail -f logs/app.log | grep ERROR
```

### Tests et validation

```bash
# Tester l'API avec curl
curl -X GET http://localhost:8000/docs

# Tester l'authentification
curl -X POST http://localhost:8000/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email":"test@example.com","password":"password"}'

# Tester l'upload
curl -X POST http://localhost:8000/upload/dataset \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -F "file=@test_data.csv"
```

### Commandes de diagnostic

```bash
# VÃ©rifier l'Ã©tat du serveur
curl -X GET http://localhost:8000/health

# VÃ©rifier les migrations
alembic history
alembic current

# VÃ©rifier les dÃ©pendances
pip list | grep -E "(fastapi|sqlalchemy|supabase)"

# VÃ©rifier l'espace disque
du -sh data/
du -sh logs/

# VÃ©rifier les processus
ps aux | grep uvicorn
netstat -tlnp | grep 8000
```

### Logs structurÃ©s pour debugging

```python
# Activer les logs SQL (attention en production)
logging.getLogger('sqlalchemy.engine').setLevel(logging.INFO)

# Logger personnalisÃ© pour les gÃ©nÃ©rations
import logging
logger = logging.getLogger(__name__)

logger.info("Starting generation", extra={
    "user_id": user.id,
    "model_type": config.model_type,
    "sample_size": config.sample_size
})
```
### Performance debugging

```bash
# Profiling d'une requÃªte spÃ©cifique
pip install py-spy
py-spy record -o profile.svg -d 30 -p $(pgrep -f uvicorn)

# Monitoring mÃ©moire
pip install memory-profiler
python -m memory_profiler app/main.py

# Analyse des requÃªtes SQL lentes
# Activer log_min_duration_statement dans postgresql.conf
```

## ğŸš€ DÃ©ploiement et Production

### DÃ©ploiement local avec Docker

```dockerfile
# Dockerfile
FROM python:3.12-slim

WORKDIR /app

# Installer les dÃ©pendances systÃ¨me
RUN apt-get update && apt-get install -y \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Copier et installer les dÃ©pendances Python
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copier le code source
COPY . .

# Variables d'environnement
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1

# Port
EXPOSE 8000

# Commande de dÃ©marrage
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql+psycopg2://postgres:password@db:5432/synth_db
      - ASYNC_DATABASE_URL=postgresql+asyncpg://postgres:password@db:5432/synth_db
    depends_on:
      - db
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs

  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=synth_db
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

volumes:
  postgres_data:
```

### DÃ©ploiement en production

#### 1. Configuration serveur

```bash
# Installation sur Ubuntu/Debian
sudo apt update
sudo apt install -y python3.12 python3-pip postgresql nginx

# CrÃ©ation utilisateur application
sudo useradd -m -s /bin/bash synthapp
sudo usermod -aG sudo synthapp
```

#### 2. Configuration Gunicorn

```python
# gunicorn.conf.py
bind = "0.0.0.0:8000"
workers = 4
worker_class = "uvicorn.workers.UvicornWorker"
worker_connections = 1000
max_requests = 1000
max_requests_jitter = 100
timeout = 120
keepalive = 5
preload_app = True
```

```bash
# DÃ©marrage avec Gunicorn
gunicorn app.main:app -c gunicorn.conf.py
```

#### 3. Configuration Nginx

```nginx
# /etc/nginx/sites-available/synth-backend
server {
    listen 80;
    server_name your-domain.com;

    client_max_body_size 500M;

    location / {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_read_timeout 120s;
        proxy_connect_timeout 120s;
        proxy_send_timeout 120s;
    }

    location /static/ {
        alias /var/www/synth-backend/static/;
    }
}
```

#### 4. Service systemd

```ini
# /etc/systemd/system/synth-backend.service
[Unit]
Description=Synthetic Data Generation Backend
After=network.target

[Service]
Type=notify
User=synthapp
Group=synthapp
WorkingDirectory=/home/synthapp/synth-backend
Environment=PATH=/home/synthapp/synth-backend/venv/bin
ExecStart=/home/synthapp/synth-backend/venv/bin/gunicorn app.main:app -c gunicorn.conf.py
ExecReload=/bin/kill -s HUP $MAINPID
KillMode=mixed
TimeoutStopSec=5
PrivateTmp=true
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

```bash
# Activation du service
sudo systemctl enable synth-backend
sudo systemctl start synth-backend
sudo systemctl status synth-backend
```

### Configuration SSL avec Let's Encrypt

```bash
# Installation Certbot
sudo apt install -y certbot python3-certbot-nginx

# Obtention du certificat
sudo certbot --nginx -d your-domain.com

# Renouvellement automatique
sudo crontab -e
# Ajouter : 0 12 * * * /usr/bin/certbot renew --quiet
```

### Monitoring et logs en production

```bash
# Logs application
sudo journalctl -u synth-backend -f

# Logs Nginx
sudo tail -f /var/log/nginx/access.log
sudo tail -f /var/log/nginx/error.log

# Monitoring des ressources
htop
df -h
free -h
```

### Sauvegarde automatique

```bash
#!/bin/bash
# backup.sh
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backup/synth-backend"

# Sauvegarde de la base de donnÃ©es
pg_dump -h localhost -U postgres synth_db > "$BACKUP_DIR/db_$DATE.sql"

# Sauvegarde des fichiers uploadÃ©s
tar -czf "$BACKUP_DIR/data_$DATE.tar.gz" /home/synthapp/synth-backend/data/

# Nettoyage des anciennes sauvegardes (> 7 jours)
find "$BACKUP_DIR" -name "*.sql" -mtime +7 -delete
find "$BACKUP_DIR" -name "*.tar.gz" -mtime +7 -delete
```

### Checklist de dÃ©ploiement

- [ ] Variables d'environnement configurÃ©es
- [ ] Base de donnÃ©es initialisÃ©e et migrÃ©e
- [ ] Supabase bucket crÃ©Ã© et configurÃ©
- [ ] Nginx configurÃ© avec SSL
- [ ] Service systemd activÃ©
- [ ] Logs rotatifs configurÃ©s
- [ ] Sauvegardes automatiques programmÃ©es
- [ ] Monitoring mis en place
- [ ] Tests de charge effectuÃ©s

## ğŸ›  Contribution et DÃ©veloppement

### Standards de dÃ©veloppement

#### Structure du code
- **PEP 8** pour le style Python
- **Type hints** obligatoires pour toutes les fonctions
- **Docstrings** au format Google
- **Tests unitaires** pour toute nouvelle fonctionnalitÃ©

#### Pre-commit hooks
```bash
# Installation
pip install pre-commit
pre-commit install

# Configuration .pre-commit-config.yaml
repos:
  - repo: https://github.com/psf/black
    rev: 23.3.0
    hooks:
      - id: black
  - repo: https://github.com/pycqa/flake8
    rev: 6.0.0
    hooks:
      - id: flake8
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.3.0
    hooks:
      - id: mypy
```

### Workflow de dÃ©veloppement

1. **Fork** du repository
2. **CrÃ©er une branche** feature/bugfix
3. **DÃ©velopper** avec tests
4. **Commit** avec messages conventionnels
5. **Push** et crÃ©er une Pull Request

#### Messages de commit conventionnels
```bash
feat: add Bayesian optimization for TVAE models
fix: resolve memory leak in dataset processing
docs: update API documentation for v2 endpoints
refactor: improve error handling in auth module
test: add integration tests for optimization service
```

### Architecture des tests

```bash
tests/
â”œâ”€â”€ unit/                    # Tests unitaires
â”‚   â”œâ”€â”€ test_auth.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_services.py
â”œâ”€â”€ integration/             # Tests d'intÃ©gration
â”‚   â”œâ”€â”€ test_api_endpoints.py
â”‚   â””â”€â”€ test_database.py
â”œâ”€â”€ e2e/                     # Tests end-to-end
â”‚   â””â”€â”€ test_generation_flow.py
â”œâ”€â”€ fixtures/                # DonnÃ©es de test
â”‚   â””â”€â”€ sample_datasets/
â””â”€â”€ conftest.py             # Configuration pytest
```

### Exemples de tests

```python
# tests/unit/test_generation_service.py
import pytest
from app.services.generation_service import GenerationService
from app.schemas.DataRequest import DataRequestCreate

@pytest.fixture
def generation_service():
    return GenerationService()

@pytest.fixture
def sample_request():
    return DataRequestCreate(
        model_type="ctgan",
        sample_size=1000,
        epochs=10
    )

def test_ctgan_generation(generation_service, sample_request):
    """Test CTGAN model generation"""
    result = generation_service.generate_synthetic_data(sample_request)
    
    assert result.success is True
    assert len(result.synthetic_data) == 1000
    assert result.metadata.model_type == "ctgan"

def test_invalid_model_type(generation_service):
    """Test handling of invalid model type"""
    with pytest.raises(ValueError, match="Unsupported model type"):
        invalid_request = DataRequestCreate(
            model_type="invalid_model",
            sample_size=1000
        )
        generation_service.generate_synthetic_data(invalid_request)
```

### Configuration pour le dÃ©veloppement

```bash
# Installation environnement de dÃ©veloppement
pip install -r requirements.txt
pip install -r requirements-dev.txt  # Si disponible

# Variables d'environnement pour dev
export DEBUG=True
export LOG_LEVEL=DEBUG
export DATABASE_URL=postgresql+psycopg2://postgres:password@localhost:5432/synth_db_dev

# Base de donnÃ©es de test
createdb synth_db_test
export TEST_DATABASE_URL=postgresql+psycopg2://postgres:password@localhost:5432/synth_db_test
```

### Commandes de dÃ©veloppement utiles

```bash
# Formatage du code
black app/ tests/
isort app/ tests/

# Linting
flake8 app/ tests/
pylint app/

# Type checking
mypy app/

# Tests avec coverage
pytest --cov=app tests/
coverage html  # GÃ©nÃ©rer rapport HTML

# Tests de performance
pytest --benchmark-only tests/benchmarks/

# Profile d'une fonction spÃ©cifique
python -m cProfile -o profile.stats app/main.py
```

### Debugging avancÃ©

```python
# Utilisation du debugger
import pdb; pdb.set_trace()

# Avec IPython (plus avancÃ©)
import IPython; IPython.embed()

# Logging pour debugging
import logging
logger = logging.getLogger(__name__)

def complex_function():
    logger.debug("Starting complex operation")
    # ... code ...
    logger.debug(f"Intermediate result: {result}")
    # ... more code ...
    logger.debug("Operation completed successfully")
```

### IntÃ©gration continue

Exemple de configuration GitHub Actions :

```yaml
# .github/workflows/tests.yml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: synth_db_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest pytest-cov
    
    - name: Run tests
      run: |
        pytest --cov=app tests/
      env:
        DATABASE_URL: postgresql+psycopg2://postgres:postgres@localhost:5432/synth_db_test
```

## ğŸ“ Support et Contact

### FAQ - Questions FrÃ©quentes

#### **Q: Comment augmenter la qualitÃ© des donnÃ©es gÃ©nÃ©rÃ©es ?**
A: Essayez ces approches :
- Augmentez le nombre d'`epochs` (100-300 pour CTGAN)
- Utilisez l'optimisation BayÃ©sienne pour trouver les meilleurs paramÃ¨tres
- Assurez-vous que votre dataset d'origine est suffisamment grand (>1000 lignes)
- VÃ©rifiez que les colonnes catÃ©gorielles sont bien dÃ©tectÃ©es

#### **Q: Pourquoi ma gÃ©nÃ©ration est-elle si lente ?**
A: Plusieurs facteurs peuvent causer des lenteurs :
- Taille du `batch_size` trop petite (essayez 500-1000)
- Nombre d'`epochs` trop Ã©levÃ© pour un test
- Dataset trÃ¨s volumineux (>100MB)
- Ressources insuffisantes sur le serveur

#### **Q: Comment gÃ©rer les erreurs de mÃ©moire ?**
A: Solutions possibles :
- RÃ©duisez la `sample_size` gÃ©nÃ©rÃ©e
- Diminuez le `batch_size` du modÃ¨le
- Utilisez `TVAE` au lieu de `CTGAN` (moins gourmand)
- Augmentez la RAM du serveur

#### **Q: Les donnÃ©es gÃ©nÃ©rÃ©es ne ressemblent pas aux originales**
A: VÃ©rifications Ã  faire :
- Le dataset original est-il assez diversifiÃ© ?
- Y a-t-il des colonnes avec beaucoup de valeurs manquantes ?
- Les types de donnÃ©es sont-ils correctement dÃ©tectÃ©s ?
- Essayez d'augmenter les `epochs` ou utilisez l'optimisation

#### **Q: Comment sÃ©curiser l'API en production ?**
A: Mesures recommandÃ©es :
- Utilisez HTTPS uniquement
- Configurez des secrets robustes (32+ caractÃ¨res)
- Activez les limitations de taux (rate limiting)
- Mettez Ã  jour rÃ©guliÃ¨rement les dÃ©pendances
- Surveillez les logs d'erreurs

### Ressources et Documentation

#### Documentation technique
- **API Interactive :** [http://localhost:8000/docs](http://localhost:8000/docs)
- **SchÃ©mas de donnÃ©es :** [http://localhost:8000/redoc](http://localhost:8000/redoc)
- **SDV Documentation :** [https://docs.sdv.dev/](https://docs.sdv.dev/)
- **FastAPI Guide :** [https://fastapi.tiangolo.com/](https://fastapi.tiangolo.com/)

#### DÃ©pendances principales
- **FastAPI :** Framework web moderne et rapide
- **SQLAlchemy :** ORM pour la gestion de base de donnÃ©es
- **SDV :** Suite de gÃ©nÃ©ration de donnÃ©es synthÃ©tiques
- **Supabase :** Backend-as-a-Service pour le stockage
- **Pydantic :** Validation et sÃ©rialisation des donnÃ©es

### Roadmap et AmÃ©liorations Futures

#### Version 1.1 (Q1 2025)
- [ ] Support des modÃ¨les GAN conditionnels avancÃ©s
- [ ] IntÃ©gration avec MLflow pour le tracking des expÃ©riences
- [ ] API GraphQL en complÃ©ment du REST
- [ ] Support des datasets distribuÃ©s (Dask)

#### Version 1.2 (Q2 2025)
- [ ] GÃ©nÃ©ration de donnÃ©es temporelles (time series)
- [ ] Support des donnÃ©es textuelles (NLP)
- [ ] IntÃ©gration avec des modÃ¨les LLM pour la gÃ©nÃ©ration
- [ ] Dashboard analytics avancÃ©

#### Version 2.0 (Q3 2025)
- [ ] Architecture microservices
- [ ] Support Kubernetes natif
- [ ] API streaming pour la gÃ©nÃ©ration en temps rÃ©el
- [ ] IntÃ©gration blockchain pour la traÃ§abilitÃ©

### Contribution au Projet

#### Comment contribuer
1. **Issues :** Signalez des bugs ou proposez des amÃ©liorations
2. **Pull Requests :** Soumettez du code aprÃ¨s avoir crÃ©Ã© une issue
3. **Documentation :** AmÃ©liorez la documentation existante
4. **Tests :** Ajoutez des tests pour augmenter la couverture

#### Guidelines de contribution
- Suivez les standards PEP 8 pour Python
- Ajoutez des tests pour toute nouvelle fonctionnalitÃ©
- Documentez les fonctions publiques
- Utilisez des messages de commit conventionnels

### Licence et Mentions LÃ©gales

Ce projet est distribuÃ© sous licence MIT. Voir le fichier [LICENSE](../LICENSE) pour plus de dÃ©tails.

#### CrÃ©dits
- **SDV Team :** Pour la suite de gÃ©nÃ©ration de donnÃ©es synthÃ©tiques
- **FastAPI Team :** Pour le framework web moderne
- **Supabase Team :** Pour les services backend
- **CommunautÃ© Open Source :** Pour les nombreuses dÃ©pendances utilisÃ©es

---

**Version Backend :** 1.0.0  
**DerniÃ¨re mise Ã  jour :** 13 aoÃ»t 2025  
**CompatibilitÃ© Python :** 3.9+  
**Statut :** Production Ready  

**DÃ©veloppÃ© avec â¤ï¸ pour la gÃ©nÃ©ration de donnÃ©es synthÃ©tiques**
