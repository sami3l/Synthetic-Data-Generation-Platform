# Backend - Synthetic Data Generation Platform

## ğŸ¯ Vue d'ensemble

API Backend FastAPI pour une plateforme complÃ¨te de gÃ©nÃ©ration de donnÃ©es synthÃ©tiques utilisant l'intelligence artificielle. Cette plateforme supporte plusieurs modÃ¨les d'IA (CTGAN, TVAE) avec des fonctionnalitÃ©s avancÃ©es d'optimisation bayÃ©sienne et de stockage cloud via Supabase.

La plateforme est conÃ§ue pour permettre aux utilisateurs de :
- Uploader des datasets dans diffÃ©rents formats
- Configurer des modÃ¨les de gÃ©nÃ©ration de donnÃ©es synthÃ©tiques
- Optimiser automatiquement les hyperparamÃ¨tres
- TÃ©lÃ©charger les donnÃ©es gÃ©nÃ©rÃ©es
- Suivre les performances et les mÃ©triques

## ğŸš€ FonctionnalitÃ©s Principales

### ğŸ¤– GÃ©nÃ©ration de DonnÃ©es SynthÃ©tiques
- **ModÃ¨les IA supportÃ©s :**
  - **CTGAN** (Conditional Tabular GAN) - GÃ©nÃ©ration conditionnelle de donnÃ©es tabulaires
  - **TVAE** (Tabular Variational AutoEncoder) - GÃ©nÃ©ration basÃ©e sur les autoencodeurs variationnels
- **Optimisation BayÃ©sienne** - Optimisation automatique des hyperparamÃ¨tres    
- **Configuration flexible** - ParamÃ¨tres personnalisables par modÃ¨le

### ğŸ“Š Optimisation des HyperparamÃ¨tres  
- **Grid Search** - Recherche exhaustive dans une grille de paramÃ¨tres
- **Random Search** - Recherche alÃ©atoire optimisÃ©e
- **Optimisation BayÃ©sienne** avec scikit-optimize pour une recherche intelligente
- **MÃ©triques de qualitÃ©** automatiques pour Ã©valuer les rÃ©sultats

### ğŸ“ Gestion des DonnÃ©es
- **Upload multi-format :** CSV, JSON, Excel (.xlsx), 
- **Validation automatique** des datasets uploadÃ©s
- **Analyse des types de donnÃ©es** et dÃ©tection des colonnes catÃ©gorielles
- **Stockage sÃ©curisÃ©** avec Supabase Storage
- **URLs temporaires** pour tÃ©lÃ©chargement sÃ©curisÃ© des rÃ©sultats

### ğŸ” SÃ©curitÃ© et Authentification
- **JWT Authentication** avec tokens d'accÃ¨s et de rafraÃ®chissement
- **Gestion des rÃ´les** (utilisateur standard/administrateur)
- **Middleware de sÃ©curitÃ©** avec headers automatiques
- **Limitation de taille** des requÃªtes et fichiers uploadÃ©s
- **CORS configurÃ©** pour l'intÃ©gration frontend

### ğŸ“ˆ Monitoring et Analytics
- **Logging complet** de toutes les requÃªtes et opÃ©rations
- **Statistiques de performance** en temps rÃ©el
- **Dashboard analytique** pour les administrateurs
- **Suivi des requÃªtes** par utilisateur
- **MÃ©triques de gÃ©nÃ©ration** et d'optimisation

### ğŸ‘¥ Gestion des Utilisateurs et Administration
- **Profils utilisateur** avec informations dÃ©taillÃ©es
- **SystÃ¨me de notifications** push intÃ©grÃ©
- **Logs d'actions admin** pour traÃ§abilitÃ©
- **Gestion des datasets** uploadÃ©s par utilisateur
- **Approbation des requÃªtes** par les administrateurs

## ğŸ›  Architecture Technique

### Stack Technologique
- **Framework :** FastAPI avec support asynchrone
- **Base de donnÃ©es :** PostgreSQL avec SQLAlchemy 2.0
- **IA/ML :** SDV (Synthetic Data Vault), scikit-optimize, pandas, numpy
- **Stockage cloud :** Supabase Storage
- **Authentification :** JWT avec python-jose[cryptography]
- **Migrations :** Alembic pour la gestion des versions DB
- **Validation :** Pydantic v2 pour les schÃ©mas de donnÃ©es

### Architecture des ModÃ¨les
La plateforme utilise une architecture modulaire avec :
- **ModÃ¨les SQLAlchemy** pour la persistance des donnÃ©es
- **Services mÃ©tier** pour la logique applicative
- **Routeurs FastAPI** pour les endpoints API
- **SchÃ©mas Pydantic** pour la validation et sÃ©rialisation
- **DÃ©pendances** pour l'injection et l'authentification

### Structure DÃ©taillÃ©e du Projet
```
synth-backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                    # Point d'entrÃ©e FastAPI
â”‚   â”œâ”€â”€ ai/                        # Services IA et modÃ¨les
â”‚   â”‚   â”œâ”€â”€ models/                # DÃ©finitions des modÃ¨les IA
â”‚   â”‚   â””â”€â”€ services/              # Services de gÃ©nÃ©ration
â”‚   â”œâ”€â”€ auth/                      # Authentification JWT
â”‚   â”‚   â””â”€â”€ jwt.py                 # Gestion des tokens
â”‚   â”œâ”€â”€ core/                      # Configuration centrale
â”‚   â”‚   â”œâ”€â”€ config.py              # Variables d'environnement
â”‚   â”‚   â”œâ”€â”€ middleware.py          # Middlewares personnalisÃ©s
â”‚   â”‚   â”œâ”€â”€ security.py            # Utilitaires de sÃ©curitÃ©
â”‚   â”‚   â””â”€â”€ supabase.py            # Client Supabase
â”‚   â”œâ”€â”€ data/                      # Stockage des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ datasets/              # Datasets uploadÃ©s
â”‚   â”‚   â””â”€â”€ synthetic/             # DonnÃ©es gÃ©nÃ©rÃ©es
â”‚   â”œâ”€â”€ db/                        # Configuration base de donnÃ©es
â”‚   â”‚   â”œâ”€â”€ database.py            # Connexion SQLAlchemy
â”‚   â”‚   â”œâ”€â”€ deps.py                # DÃ©pendances DB
â”‚   â”‚   â””â”€â”€ session.py             # Gestion des sessions
â”‚   â”œâ”€â”€ dependencies/              # DÃ©pendances FastAPI
â”‚   â”‚   â”œâ”€â”€ auth.py                # DÃ©pendances d'authentification
â”‚   â”‚   â””â”€â”€ roles.py               # Gestion des rÃ´les
â”‚   â”œâ”€â”€ models/                    # ModÃ¨les SQLAlchemy
â”‚   â”‚   â”œâ”€â”€ DataRequest.py         # RequÃªtes de gÃ©nÃ©ration
â”‚   â”‚   â”œâ”€â”€ user.py                # Utilisateurs
â”‚   â”‚   â”œâ”€â”€ UserProfile.py         # Profils utilisateur
â”‚   â”‚   â”œâ”€â”€ UploadedDataset.py     # Datasets uploadÃ©s
â”‚   â”‚   â”œâ”€â”€ Notification.py        # Notifications
â”‚   â”‚   â”œâ”€â”€ AdminActionLog.py      # Logs administrateur
â”‚   â”‚   â””â”€â”€ Optimization*.py       # ModÃ¨les d'optimisation
â”‚   â”œâ”€â”€ routers/                   # Endpoints API
â”‚   â”‚   â”œâ”€â”€ auth.py                # Authentification
â”‚   â”‚   â”œâ”€â”€ data.py                # Gestion des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ dataset.py             # Gestion des datasets
â”‚   â”‚   â”œâ”€â”€ generation.py          # GÃ©nÃ©ration v1
â”‚   â”‚   â”œâ”€â”€ generation_v2.py       # GÃ©nÃ©ration v2 amÃ©liorÃ©e
â”‚   â”‚   â”œâ”€â”€ optimization.py        # Optimisation bayÃ©sienne
â”‚   â”‚   â”œâ”€â”€ upload_async.py        # Upload asynchrone
â”‚   â”‚   â”œâ”€â”€ user.py                # Gestion utilisateurs
â”‚   â”‚   â”œâ”€â”€ admin.py               # Administration
â”‚   â”‚   â”œâ”€â”€ notification.py        # Notifications
â”‚   â”‚   â””â”€â”€ stats.py               # Statistiques
â”‚   â”œâ”€â”€ schemas/                   # SchÃ©mas Pydantic
â”‚   â”‚   â”œâ”€â”€ user.py                # SchÃ©mas utilisateur
â”‚   â”‚   â”œâ”€â”€ DataRequest.py         # SchÃ©mas de requÃªtes
â”‚   â”‚   â”œâ”€â”€ datasets.py            # SchÃ©mas datasets
â”‚   â”‚   â”œâ”€â”€ Optimization.py        # SchÃ©mas optimisation
â”‚   â”‚   â””â”€â”€ Notification.py        # SchÃ©mas notifications
â”‚   â””â”€â”€ services/                  # Services mÃ©tier
â”œâ”€â”€ alembic/                       # Migrations de base de donnÃ©es
â”‚   â”œâ”€â”€ versions/                  # Fichiers de migration
â”‚   â””â”€â”€ env.py                     # Configuration Alembic
â”œâ”€â”€ requirements.txt               # DÃ©pendances Python
â”œâ”€â”€ requirements-minimal.txt       # DÃ©pendances minimales
â”œâ”€â”€ .env.example                   # Template variables d'environnement
â””â”€â”€ alembic.ini                    # Configuration Alembic
```

## ğŸš€ Installation et Configuration

### 1. PrÃ©requis
```bash
Python 3.9+ (recommandÃ© 3.12+)
PostgreSQL 12+
pip (gestionnaire de paquets Python)
```

### 2. Installation rapide
```bash
# 1. Cloner le repository et naviguer vers le backend
cd synth-backend

# 2. CrÃ©er un environnement virtuel (recommandÃ©)
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Configurer les variables d'environnement
copy .env.example .env
# Ã‰diter le fichier .env avec vos paramÃ¨tres

# 5. Initialiser la base de donnÃ©es
alembic upgrade head

# 6. DÃ©marrer le serveur de dÃ©veloppement
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 3. Configuration de l'environnement

Copiez `.env.example` vers `.env` et configurez les variables suivantes :

```env
# Base de donnÃ©es PostgreSQL
DATABASE_URL=postgresql+psycopg2://username:password@localhost:5432/synth_db
ASYNC_DATABASE_URL=postgresql+asyncpg://username:password@localhost:5432/synth_db

# JWT Authentication
SECRET_KEY=your-super-secret-jwt-key-here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Supabase (pour le stockage cloud)
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-supabase-anon-key
SUPABASE_BUCKET_NAME=synthetic-datasets

# Configuration application
APP_NAME=Synthetic Data Generation Platform
APP_VERSION=1.0.0
DEBUG=True

# Limites de fichiers
MAX_FILE_SIZE_MB=500
SUPPORTED_FILE_TYPES=csv,json,xlsx,parquet

# Configuration gÃ©nÃ©ration
DEFAULT_SAMPLE_SIZE=1000
MAX_SAMPLE_SIZE=100000
DEFAULT_EPOCHS=100
MAX_EPOCHS=500
```

### 4. Configuration de la base de donnÃ©es

```bash
# CrÃ©er la base de donnÃ©es PostgreSQL
createdb synth_db

# Ou via psql
psql -U postgres -c "CREATE DATABASE synth_db;"

# ExÃ©cuter les migrations
alembic upgrade head

# VÃ©rifier les tables crÃ©Ã©es
alembic current
```

## ğŸ“‹ Commandes Utiles

### Gestion de l'application
```bash
# DÃ©marrer le serveur de dÃ©veloppement
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# DÃ©marrer en mode production
uvicorn app.main:app --host 0.0.0.0 --port 8000

# Avec Gunicorn (production)
gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

### Gestion des migrations Alembic
```bash
# CrÃ©er une nouvelle migration
alembic revision --autogenerate -m "Description de la migration"

# Appliquer toutes les migrations
alembic upgrade head

# Voir l'historique des migrations
alembic history

# Revenir Ã  une migration spÃ©cifique
alembic downgrade <revision_id>

# Voir le statut actuel
alembic current
```

### Gestion des dÃ©pendances
```bash
# Installer les dÃ©pendances complÃ¨tes
pip install -r requirements.txt

# Installer les dÃ©pendances minimales
pip install -r requirements-minimal.txt

# Mettre Ã  jour requirements.txt
pip freeze > requirements.txt

# Installer une nouvelle dÃ©pendance
pip install package_name
pip freeze > requirements.txt
```

## ğŸ”§ Configuration AvancÃ©e

### Variables d'environnement complÃ¨tes

```env
# === BASE DE DONNÃ‰ES ===
DATABASE_URL=postgresql+psycopg2://username:password@localhost:5432/synth_db
ASYNC_DATABASE_URL=postgresql+asyncpg://username:password@localhost:5432/synth_db

# === AUTHENTIFICATION JWT ===
SECRET_KEY=your-super-secret-jwt-key-minimum-32-characters
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# === SUPABASE STORAGE ===
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-supabase-service-role-key
SUPABASE_BUCKET_NAME=synthetic-datasets

# === CONFIGURATION APPLICATION ===
APP_NAME=Synthetic Data Generation Platform
APP_VERSION=1.0.0
DEBUG=True
ENVIRONMENT=development  # development, staging, production

# === LIMITES ET RESTRICTIONS ===
MAX_FILE_SIZE_MB=500
SUPPORTED_FILE_TYPES=csv,json,xlsx,parquet
MAX_CONCURRENT_GENERATIONS=5
REQUEST_TIMEOUT_SECONDS=3600

# === GÃ‰NÃ‰RATION DE DONNÃ‰ES ===
DEFAULT_SAMPLE_SIZE=1000
MAX_SAMPLE_SIZE=100000
MIN_SAMPLE_SIZE=100
DEFAULT_EPOCHS=100
MAX_EPOCHS=500
MIN_EPOCHS=10

# === OPTIMISATION ===
MAX_OPTIMIZATION_TRIALS=100
DEFAULT_OPTIMIZATION_TRIALS=20
OPTIMIZATION_TIMEOUT_HOURS=24

# === SÃ‰CURITÃ‰ ===
CORS_ORIGINS=http://localhost:3000,http://localhost:8081
ALLOWED_HOSTS=localhost,127.0.0.1
MAX_REQUEST_SIZE_MB=100

# === LOGGING ===
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR
LOG_FILE_PATH=logs/app.log
LOG_ROTATION_SIZE_MB=10
LOG_BACKUP_COUNT=5

# === NOTIFICATIONS ===
ENABLE_PUSH_NOTIFICATIONS=true
NOTIFICATION_BATCH_SIZE=100

# === MONITORING ===
METRICS_ENABLED=true
PERFORMANCE_MONITORING=true
```

### Configuration Supabase

Pour configurer Supabase Storage :

1. **CrÃ©er un bucket :**
```sql
-- Dans l'interface Supabase SQL Editor
INSERT INTO storage.buckets (id, name, public)
VALUES ('synthetic-datasets', 'synthetic-datasets', false);
```

2. **Configurer les politiques RLS :**
```sql
-- Politique pour permettre l'upload aux utilisateurs authentifiÃ©s
CREATE POLICY "Users can upload their own datasets" ON storage.objects
FOR INSERT WITH CHECK (
  bucket_id = 'synthetic-datasets' AND
  auth.uid()::text = (storage.foldername(name))[1]
);

-- Politique pour permettre le tÃ©lÃ©chargement
CREATE POLICY "Users can download their own datasets" ON storage.objects
FOR SELECT USING (
  bucket_id = 'synthetic-datasets' AND
  auth.uid()::text = (storage.foldername(name))[1]
);
```

### Configuration PostgreSQL

Configuration optimale pour PostgreSQL :

```sql
-- postgresql.conf recommandations
shared_buffers = 256MB
effective_cache_size = 1GB
work_mem = 4MB
maintenance_work_mem = 64MB
checkpoint_segments = 32
checkpoint_completion_target = 0.7
wal_buffers = 16MB
default_statistics_target = 100
```

### Middleware et sÃ©curitÃ©

Le backend inclut plusieurs middlewares de sÃ©curitÃ© :

```python
# Middlewares automatiquement appliquÃ©s
SecurityHeadersMiddleware     # Headers de sÃ©curitÃ©
RequestSizeLimitMiddleware   # Limite taille requÃªtes
LoggingMiddleware           # Logging automatique
PerformanceMonitoringMiddleware # MÃ©triques de performance
CORSMiddleware             # Configuration CORS
```

### Configuration des logs

```python
# Configuration logging dans main.py
logging.basicConfig(
    level=getattr(logging, os.getenv('LOG_LEVEL', 'INFO')),
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(os.getenv('LOG_FILE_PATH', 'logs/app.log')),
        logging.StreamHandler()
    ]
)
```

## ğŸ“š API Documentation

L'API est entiÃ¨rement documentÃ©e et accessible via :
- **Swagger UI :** `http://localhost:8000/docs` (interface interactive)
- **ReDoc :** `http://localhost:8000/redoc` (documentation statique)

### Endpoints principaux

#### ğŸ” Authentification (`/auth`)
```http
POST /auth/register          # Inscription d'un nouvel utilisateur
POST /auth/login             # Connexion et gÃ©nÃ©ration de token
POST /auth/refresh           # RafraÃ®chissement du token
GET  /auth/me                # RÃ©cupÃ©ration du profil utilisateur
POST /auth/logout            # DÃ©connexion
```

#### ğŸ‘¤ Gestion des utilisateurs (`/users`)
```http
GET    /users/profile        # Profil de l'utilisateur connectÃ©
PUT    /users/profile        # Mise Ã  jour du profil
POST   /users/push-token     # Enregistrement token push notifications
DELETE /users/account        # Suppression du compte
```

#### ğŸ“¤ Upload de donnÃ©es (`/upload`)
```http
POST /upload/dataset         # Upload d'un dataset (CSV, JSON, Excel, Parquet)
GET  /upload/datasets        # Liste des datasets de l'utilisateur
GET  /upload/datasets/{id}   # DÃ©tails d'un dataset spÃ©cifique
DELETE /upload/datasets/{id} # Suppression d'un dataset
```

#### ğŸ¤– GÃ©nÃ©ration de donnÃ©es (`/generation`)
```http
POST /generation/start       # DÃ©marrer une nouvelle gÃ©nÃ©ration
GET  /generation/requests    # Liste des requÃªtes de l'utilisateur
GET  /generation/status/{id} # Statut d'une gÃ©nÃ©ration
GET  /generation/download/{id} # TÃ©lÃ©charger les rÃ©sultats
DELETE /generation/requests/{id} # Annuler une requÃªte
```

#### ğŸ”§ GÃ©nÃ©ration avancÃ©e (`/generation-v2`)
```http
POST /generation-v2/start    # GÃ©nÃ©ration avec paramÃ¨tres avancÃ©s
GET  /generation-v2/config   # Configuration par dÃ©faut
POST /generation-v2/validate # Validation des paramÃ¨tres
```

#### ğŸ“Š Optimisation (`/optimization`)
```http
POST /optimization/start     # DÃ©marrer une optimisation bayÃ©sienne
GET  /optimization/trials/{id} # RÃ©sultats des essais d'optimisation
GET  /optimization/best/{id} # Meilleurs paramÃ¨tres trouvÃ©s
PUT  /optimization/stop/{id} # ArrÃªter une optimisation en cours
```

#### ï¿½ Statistiques (`/stats`)
```http
GET /stats/dashboard         # Dashboard utilisateur
GET /stats/system           # Statistiques systÃ¨me (admin uniquement)
GET /stats/performance      # MÃ©triques de performance
GET /stats/usage            # Statistiques d'utilisation
```

#### ğŸ”” Notifications (`/notifications`)
```http
GET    /notifications        # Notifications de l'utilisateur
POST   /notifications/read   # Marquer comme lues
DELETE /notifications/{id}   # Supprimer une notification
```

#### ğŸ‘‘ Administration (`/admin`)
```http
GET    /admin/users          # Liste tous les utilisateurs
GET    /admin/requests       # Toutes les requÃªtes de gÃ©nÃ©ration
POST   /admin/approve/{id}   # Approuver une requÃªte
POST   /admin/reject/{id}    # Rejeter une requÃªte
GET    /admin/logs           # Logs d'actions administrateur
POST   /admin/users/{id}/toggle # Activer/dÃ©sactiver un utilisateur
```

### Authentification

La plupart des endpoints nÃ©cessitent une authentification via JWT :

```http
Authorization: Bearer <your-jwt-token>
```

### Formats de rÃ©ponse

Toutes les rÃ©ponses suivent un format standardisÃ© :

```json
{
  "success": true,
  "data": { ... },
  "message": "Operation completed successfully",
  "timestamp": "2024-12-13T10:30:00Z"
}
```

En cas d'erreur :
```json
{
  "success": false,
  "error": {
    "code": "VALIDATION_ERROR",
    "message": "Invalid input parameters",
    "details": { ... }
  },
  "timestamp": "2024-12-13T10:30:00Z"
}
```

## ğŸ¯ Configuration des ModÃ¨les de GÃ©nÃ©ration

### CTGAN (Conditional Tabular GAN)

Le modÃ¨le CTGAN est optimal pour les donnÃ©es tabulaires avec des relations complexes :

```json
{
  "model_type": "ctgan",
  "epochs": 100,              // Nombre d'Ã©poques d'entraÃ®nement
  "batch_size": 500,          // Taille des lots
  "generator_dim": [256, 256], // Architecture du gÃ©nÃ©rateur
  "discriminator_dim": [256, 256], // Architecture du discriminateur
  "generator_lr": 2e-4,       // Taux d'apprentissage du gÃ©nÃ©rateur
  "discriminator_lr": 2e-4,   // Taux d'apprentissage du discriminateur
  "discriminator_steps": 1,   // Ã‰tapes d'entraÃ®nement du discriminateur
  "log_frequency": true,      // Logging des mÃ©triques
  "pac": 10                   // Facteur PAC (packing)
}
```

**ParamÃ¨tres recommandÃ©s selon la taille du dataset :**
- **Petit dataset (< 1000 lignes) :** epochs=200, batch_size=100
- **Dataset moyen (1000-10000) :** epochs=150, batch_size=500
- **Grand dataset (> 10000) :** epochs=100, batch_size=1000

### TVAE (Tabular Variational AutoEncoder)

Le modÃ¨le TVAE est plus rapide et efficace pour les datasets simples :

```json
{
  "model_type": "tvae",
  "epochs": 100,
  "batch_size": 500,
  "embedding_dim": 128,       // Dimension de l'espace latent
  "compress_dims": [128, 128], // Architecture de l'encodeur
  "decompress_dims": [128, 128], // Architecture du dÃ©codeur
  "l2scale": 1e-5,           // RÃ©gularisation L2
  "learning_rate": 1e-3,     // Taux d'apprentissage
  "loss_factor": 2           // Facteur de pondÃ©ration de la perte
}
```

### Optimisation BayÃ©sienne

Configuration pour l'optimisation automatique des hyperparamÃ¨tres :

```json
{
  "model_type": "ctgan",      // ou "tvae"
  "optimization_method": "bayesian",
  "n_trials": 50,            // Nombre d'essais d'optimisation
  "optimization_metric": "quality_score", // MÃ©trique Ã  optimiser
  "search_space": {
    "epochs": [50, 200],
    "batch_size": [100, 1000],
    "learning_rate": [1e-4, 1e-2]
  },
  "acquisition_function": "EI", // Expected Improvement
  "random_state": 42
}
```

### MÃ©triques de qualitÃ© disponibles

La plateforme Ã©value automatiquement la qualitÃ© des donnÃ©es gÃ©nÃ©rÃ©es :

- **Statistical Similarity :** Comparaison des distributions statistiques
- **Correlation Preservation :** Conservation des corrÃ©lations entre variables
- **Privacy Metrics :** Mesures de protection de la vie privÃ©e
- **Machine Learning Efficacy :** Performance sur des tÃ¢ches ML

### Exemple de requÃªte complÃ¨te

```json
{
  "dataset_id": 123,
  "sample_size": 5000,
  "model_config": {
    "model_type": "ctgan",
    "epochs": 150,
    "batch_size": 500,
    "generator_dim": [256, 256],
    "discriminator_dim": [256, 256]
  },
  "optimization_config": {
    "enabled": true,
    "method": "bayesian",
    "n_trials": 20,
    "metric": "quality_score"
  },
  "output_format": "csv",
  "include_metadata": true
}
```

## ğŸ“ˆ Monitoring et Performance

### MÃ©triques surveillÃ©es automatiquement

La plateforme collecte automatiquement plusieurs mÃ©triques :

#### MÃ©triques d'API
- **Temps de rÃ©ponse** par endpoint
- **Taux de succÃ¨s/Ã©chec** des requÃªtes
- **Utilisation de la bande passante**
- **Nombre de requÃªtes concurrentes**

#### MÃ©triques de gÃ©nÃ©ration
- **Temps d'entraÃ®nement** des modÃ¨les
- **QualitÃ© des donnÃ©es gÃ©nÃ©rÃ©es**
- **Utilisation mÃ©moire** pendant la gÃ©nÃ©ration
- **Taux de succÃ¨s** des optimisations

#### MÃ©triques utilisateur
- **ActivitÃ© par utilisateur**
- **Formats de fichiers** les plus utilisÃ©s
- **Tailles de datasets** moyennes
- **DurÃ©e des sessions**

### Dashboard de monitoring

AccÃ¨s aux mÃ©triques via les endpoints :

```http
GET /stats/dashboard        # MÃ©triques utilisateur
GET /stats/system          # MÃ©triques systÃ¨me (admin)
GET /stats/performance     # Performance en temps rÃ©el
```

### Logs structurÃ©s

Tous les logs suivent un format structurÃ© pour faciliter l'analyse :

```json
{
  "timestamp": "2024-12-13T10:30:00Z",
  "level": "INFO",
  "module": "generation_service",
  "user_id": 123,
  "request_id": "req_abc123",
  "message": "Generation completed successfully",
  "metadata": {
    "model_type": "ctgan",
    "sample_size": 5000,
    "duration_seconds": 120.5
  }
}
```
## ğŸ”’ SÃ©curitÃ© et Bonnes Pratiques

### Mesures de sÃ©curitÃ© implÃ©mentÃ©es

#### Authentification et autorisation
- **JWT stateless** avec expiration automatique
- **Tokens de rafraÃ®chissement** sÃ©curisÃ©s
- **Gestion des rÃ´les** granulaire (user/admin)
- **Validation des permissions** sur chaque endpoint

#### Protection des donnÃ©es
- **Chiffrement des mots de passe** avec bcrypt
- **Validation stricte** des uploads de fichiers
- **Nettoyage automatique** des fichiers temporaires
- **URLs temporaires** pour le tÃ©lÃ©chargement


## ğŸš€ DÃ©ploiement et Production

### DÃ©ploiement local avec Docker

```dockerfile
# Dockerfile
FROM python:3.12-slim

WORKDIR /app

# Installer les dÃ©pendances systÃ¨me
RUN apt-get update && apt-get install -y \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Copier et installer les dÃ©pendances Python
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copier le code source
COPY . .

# Variables d'environnement
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1

# Port
EXPOSE 8000

# Commande de dÃ©marrage
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql+psycopg2://postgres:password@db:5432/synth_db
      - ASYNC_DATABASE_URL=postgresql+asyncpg://postgres:password@db:5432/synth_db
    depends_on:
      - db
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs

  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=synth_db
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

volumes:
  postgres_data:
```

## ğŸ“ Support et Contact

### Ressources 

#### DÃ©pendances principales
- **FastAPI :** Framework web moderne et rapide
- **SQLAlchemy :** ORM pour la gestion de base de donnÃ©es
- **SDV :** Suite de gÃ©nÃ©ration de donnÃ©es synthÃ©tiques
- **Supabase :** Backend-as-a-Service pour le stockage
- **Pydantic :** Validation et sÃ©rialisation des donnÃ©es

### AmÃ©liorations Futures

#### Version 1.2 
- [ ] GÃ©nÃ©ration de donnÃ©es temporelles (time series)
- [ ] Support des donnÃ©es textuelles (NLP)
- [ ] IntÃ©gration avec des modÃ¨les LLM pour la gÃ©nÃ©ration
- [ ] Dashboard analytics avancÃ©

#### Version 2.0 
- [ ] Architecture microservices
- [ ] Support Kubernetes natif
- [ ] API streaming pour la gÃ©nÃ©ration en temps rÃ©el
- [ ] IntÃ©gration blockchain pour la traÃ§abilitÃ©

### Licence et Mentions LÃ©gales

Ce projet est distribuÃ© sous licence MIT. Voir le fichier [LICENSE](../LICENSE) pour plus de dÃ©tails.

#### CrÃ©dits
- **SDV Team :** Pour la suite de gÃ©nÃ©ration de donnÃ©es synthÃ©tiques
- **FastAPI Team :** Pour le framework web moderne
- **Supabase Team :** Pour les services backend
- **CommunautÃ© Open Source :** Pour les nombreuses dÃ©pendances utilisÃ©es

---
**DÃ©veloppÃ© avec â¤ï¸ pour la gÃ©nÃ©ration de donnÃ©es synthÃ©tiques**
